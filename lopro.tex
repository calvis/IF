\renewcommand{\implies}{\supset}

% XXX where does this paragraph go?
In functional programming, we like to think of propositions as
types and proofs as programs. In what the authors coin the Miller
Correspondence (XXX cite), logic {\em programs} correspond to propositions
and {\em traces} correspond to proofs. If we want to write a game as an
{\em interactive logic program}, then running that program (playing that
game) should somehow correspond to {\em interactive proof search}, or
interactive theorem proving, not terribly unlike what many PL researchers
do regularly in systems like Coq, Isabelle, and Agda. Important questions
to ask in ITP come up in IF as well: at what point should reasoning be
filled in automatically? What proof strategy should that automatic
reasoning employ? In the talk we'll try to argue that the proof theoretic
ideas of {\em forward chaining} and {\em left focus} play a key role in the
IF setting.

A logic program is a set of initial facts (typically general and
hypothetical) from which new facts can be generated and queries on the
space of facts can be made. It can be viewed as an inference system and its
execution as proof search.

As a small example, consider the following Prolog (XXX cite) program to
find paths between nodes in a graph:

\begin{verbatim}
path X X.
path X Z
  :- edge X Y, path Y Z.
\end{verbatim}

<<<<<<< HEAD
Each block of code preceding a period is a {\em clause} of the program, and
the capital-letter variables are implicitly universally quantified.
The logical interpretation of this program is one in which there are atomic
predicates \verb|path(-,-)| and \verb|edge(-,-)|, and two axiomatic
propositions, 
\[\forall x.\verb|path|(x, x)\] 
and 
\[\forall x,y,z.\verb|edge|(x, y) \land \verb|path|(y, z) \implies 
\verb|path|(x, z)\]

One can create a graph by adding an additional clause for each edge (and
lowercase identifiers for specific nodes) and then run a query such as
\verb|path a X| to get a set of all the nodes reachable from $a$. The
execution of that program resembles constructing derivations of facts like
\verb|path a b| from rules in the program along with its core rules for
implication and quantification.

One could imagine beginning to design a world with the basic logic
programming toolset: you'd introduce predicates (or types) for each kind of
thing in the world, like rooms and objects and people, and you could write
predicates like \verb|visible| to determine whether the player can see an
object. But as soon as you want to talk about state change, standard logic
programming fails us. For example, if we want to turn off a light, the
visibility of certain objects goes away -- but treating the action as an
ordinary implication, the old facts stay around. Ordinary propositional
logic of the kind Prolog is based on are {\em monotonic}: learning new
facts can never erase old ones. This brings us to Linear Logic.
=======


Here's a very minimal example of an interaction in linear logic
programming.

% XXX toggle


- Intensional vs extensional definition of a game object

- Logic program execution is proof search

- A game as a logic program: interactive proof search
>>>>>>> be62ae130ea65159baecdc050827edaa9408eda2

